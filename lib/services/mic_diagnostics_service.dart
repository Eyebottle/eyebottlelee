import 'dart:async';
import 'dart:io';
import 'dart:math' as math;

import 'package:flutter/services.dart';
import 'package:path/path.dart' as path;
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';

import '../models/mic_diagnostic_result.dart';
import 'logging_service.dart';

class MicDiagnosticsService {
  MicDiagnosticsService();

  final LoggingService _logging = LoggingService();

  Future<MicDiagnosticResult> runDiagnostic({
    Duration sampleDuration = const Duration(seconds: 3),
    Duration ambientWindow = const Duration(milliseconds: 500),
  }) async {
    final timestamp = DateTime.now();
    final recorder = AudioRecorder();
    StreamSubscription<Amplitude>? subscription;
    String? tempFilePath;
    final samples = <_AmplitudeSample>[];
    double peakLinear = 0.0;

    _logging.info('ğŸ¤ ë§ˆì´í¬ ì§„ë‹¨ ì‹œì‘: sampleDuration=${sampleDuration.inSeconds}ì´ˆ');

    try {
      // 1. ê¶Œí•œ ì²´í¬
      _logging.info('ğŸ“‹ ê¶Œí•œ ì²´í¬ ì¤‘...');
      final hasPermission = await recorder.hasPermission();
      _logging.info('ê¶Œí•œ ìƒíƒœ: hasPermission=$hasPermission');

      if (hasPermission == false) {
        _logging.warning('âš ï¸ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
        return MicDiagnosticResult(
          timestamp: timestamp,
          status: MicDiagnosticStatus.permissionDenied,
          message: 'ë§ˆì´í¬ ê¶Œí•œì´ êº¼ì ¸ ìˆì–´ìš”. Windows ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ > ë§ˆì´í¬ì—ì„œ ê¶Œí•œì„ ì¼œì£¼ì„¸ìš”.',
          hints: const [
            'Windows ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ > ë§ˆì´í¬',
            'ì•± ëª©ë¡ì—ì„œ "ì•„ì´ë³´í‹€ ì§„ë£Œ ë…¹ìŒ"ì„ í—ˆìš©',
          ],
        );
      }

      // 2. ì¥ì¹˜ ëª©ë¡ í™•ì¸
      _logging.info('ğŸ” ì…ë ¥ ì¥ì¹˜ ê²€ìƒ‰ ì¤‘...');
      final devices = await recorder.listInputDevices();
      _logging.info('ë°œê²¬ëœ ì…ë ¥ ì¥ì¹˜: ${devices?.length ?? 0}ê°œ');

      if (devices != null && devices.isNotEmpty) {
        for (var i = 0; i < devices.length; i++) {
          final device = devices[i];
          _logging.info('  ì¥ì¹˜ #$i: id=${device.id}, label=${device.label}');
        }
      }

      if (devices == null || devices.isEmpty) {
        _logging.warning('âš ï¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ');
        return MicDiagnosticResult(
          timestamp: timestamp,
          status: MicDiagnosticStatus.noInputDevice,
          message: 'ë…¹ìŒ ê°€ëŠ¥í•œ ë§ˆì´í¬ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. USB ì¼€ì´ë¸”ì´ë‚˜ ë¸”ë£¨íˆ¬ìŠ¤ ì—°ê²°ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.',
          hints: const [
            'ë§ˆì´í¬ ì „ì›ì´ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸',
            'Windows ì†Œë¦¬ ì„¤ì •ì—ì„œ ì…ë ¥ ì¥ì¹˜ ì„ íƒ',
          ],
        );
      }

      // 3. ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
      final tempDir = await getTemporaryDirectory();
      final tempFileBaseName =
          'mic_diag_${timestamp.millisecondsSinceEpoch}';

      // 4. ì§„í­ ëª¨ë‹ˆí„°ë§ ì‹œì‘
      _logging.info('ğŸ“Š ì§„í­ ëª¨ë‹ˆí„°ë§ ì‹œì‘...');
      subscription = recorder
          .onAmplitudeChanged(const Duration(milliseconds: 160))
          .listen((amp) {
        final normalized = _normalizeAmplitude(amp);
        final now = DateTime.now();
        samples.add(_AmplitudeSample(now, normalized));
        if (normalized > peakLinear) {
          peakLinear = normalized;
        }
      });

      // 5. ì½”ë± ì„ íƒ
      _logging.info('ì§€ì›ë˜ëŠ” ì½”ë± í™•ì¸ ì¤‘...');

      AudioEncoder? selectedEncoder;
      final encodersToTry = <AudioEncoder>[
        AudioEncoder.aacLc,
        AudioEncoder.opus,
        AudioEncoder.wav,
      ];

      for (final encoder in encodersToTry) {
        try {
          final isSupported = await recorder.isEncoderSupported(encoder);
          if (isSupported) {
            selectedEncoder = encoder;
            _logging.info('ì„ íƒëœ ì½”ë±: ${encoder.name}');
            break;
          }
        } catch (e) {
          _logging.warning('ì½”ë± ${encoder.name} í™•ì¸ ì¤‘ ì—ëŸ¬: $e');
        }
      }

      if (selectedEncoder == null) {
        _logging.error('âŒ ì§€ì›ë˜ëŠ” ì½”ë±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
        return MicDiagnosticResult(
          timestamp: timestamp,
          status: MicDiagnosticStatus.failure,
          message: 'ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ ì½”ë±ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.',
          hints: const [
            'Windows Media Feature Pack ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”',
            'ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”',
          ],
        );
      }

      // 6. ë…¹ìŒ ì‹œì‘ (í´ë°± ë¡œì§ í¬í•¨)
      bool recordingStarted = false;
      Exception? lastError;

      // ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„ (ì„ íƒëœ ì½”ë±ì´ ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ì½”ë±ìœ¼ë¡œ)
      final fallbackEncoders = <AudioEncoder>[
        selectedEncoder,
        ...encodersToTry.where((e) => e != selectedEncoder),
      ];

      for (int attempt = 0;
          attempt < fallbackEncoders.length && !recordingStarted;
          attempt++) {
        final encoder = fallbackEncoders[attempt];
        try {
          tempFilePath = path.join(
            tempDir.path,
            '${tempFileBaseName}${_extensionForEncoder(encoder)}',
          );

          await recorder.start(
            RecordConfig(
              encoder: encoder,
              bitRate: 64000,
              sampleRate: 44100,
            ),
            path: tempFilePath,
          );

          recordingStarted = true;
          _logging.info('âœ… ë…¹ìŒ ì‹œì‘ ì„±ê³µ (ì½”ë±: ${encoder.name})');
          break;
        } catch (e, st) {
          lastError = e is Exception ? e : Exception(e.toString());
          _logging.error('[ì‹œë„ ${attempt + 1}] ë…¹ìŒ ì‹¤íŒ¨ (${encoder.name})', error: e, stackTrace: st);

          // PlatformExceptionì€ ëŒ€ë¶€ë¶„ ì½”ë±/ì„¤ì • ë¬¸ì œ â†’ ë‹¤ìŒ ì½”ë±ìœ¼ë¡œ í´ë°±
          if (e is PlatformException && attempt < fallbackEncoders.length - 1) {
            _logging.warning('ì½”ë± ì—ëŸ¬ - ë‹¤ìŒ ì½”ë±ìœ¼ë¡œ í´ë°± (${fallbackEncoders[attempt + 1].name})');
            if (tempFilePath != null) {
              final file = File(tempFilePath!);
              if (await file.exists()) {
                unawaited(file.delete());
              }
            }
            tempFilePath = null;
          } else if (e is! PlatformException) {
            // PlatformExceptionì´ ì•„ë‹Œ ì—ëŸ¬ëŠ” ì‹¬ê°í•œ ë¬¸ì œ â†’ ì¬ì‹œë„ ì¤‘ë‹¨
            _logging.error('âŒ ì½”ë±ê³¼ ë¬´ê´€í•œ ì‹¬ê°í•œ ì—ëŸ¬ ë°œìƒ - ì¬ì‹œë„ ì¤‘ë‹¨');
            break;
          }
        }
      }

      // ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ
      if (!recordingStarted) {
        _logging.error('âŒ ëª¨ë“  ì½”ë±ìœ¼ë¡œ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨');

        // ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„¸í™”
        String detailedMessage = 'ë§ˆì´í¬ ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ì–´ìš”.';
        List<String> errorHints = [];

        if (lastError != null) {
          final errorMsg = lastError.toString().toLowerCase();
          if (errorMsg.contains('codec') || errorMsg.contains('encoder') || errorMsg.contains('aac')) {
            detailedMessage = 'ì˜¤ë””ì˜¤ ì¸ì½”ë” ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆì–´ìš”.';
            errorHints = [
              'Windows Media Feature Packì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”',
              'Windows ë²„ì „ì´ N ë˜ëŠ” KN ì—ë””ì…˜ì¸ ê²½ìš° ë³„ë„ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤',
              'ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”',
            ];
          } else if (errorMsg.contains('permission')) {
            detailedMessage = 'ë§ˆì´í¬ ê¶Œí•œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.';
            errorHints = [
              'Windows ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”',
              'ë‹¤ë¥¸ ì•±ì´ ë§ˆì´í¬ë¥¼ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”',
            ];
          } else {
            errorHints = [
              'ë§ˆì´í¬ê°€ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤',
              'ë§ˆì´í¬ë¥¼ ë‹¤ì‹œ ì—°ê²°í•´ë³´ì„¸ìš”',
              'ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”',
            ];
          }
        }

        return MicDiagnosticResult(
          timestamp: timestamp,
          status: MicDiagnosticStatus.failure,
          message: detailedMessage,
          hints: errorHints.isNotEmpty ? errorHints : const ['ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”'],
        );
      }

      // 7. ìƒ˜í”Œ ìˆ˜ì§‘
      _logging.info('â±ï¸ ${sampleDuration.inSeconds}ì´ˆ ë™ì•ˆ ìƒ˜í”Œ ìˆ˜ì§‘ ì¤‘...');
      await Future<void>.delayed(sampleDuration);

      // 8. ë…¹ìŒ ì¤‘ì§€
      _logging.info('â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ì¤‘...');
      await recorder.stop();
      _logging.info('âœ… ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ');

      await subscription.cancel();
      subscription = null;

      if (tempFilePath != null) {
        final file = File(tempFilePath);
        if (await file.exists()) {
          unawaited(file.delete());
        }
      }

      // 9. ë°ì´í„° ê²€ì¦
      if (!peakLinear.isFinite || peakLinear.isNaN) {
        peakLinear = 0.0;
      }
      _logging.info('ğŸ“ˆ ìˆ˜ì§‘ëœ ìƒ˜í”Œ: ${samples.length}ê°œ, í”¼í¬ ë ˆë²¨: ${peakLinear.toStringAsFixed(4)}');

      // 10. ë©”íŠ¸ë¦­ ê³„ì‚°
      _logging.info('ğŸ§® ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...');
      final metrics = _calculateMetrics(
        samples: samples,
        sampleWindow: sampleDuration,
        ambientWindow: ambientWindow,
      );

      _logging.info('ğŸ“Š ê³„ì‚°ëœ ë©”íŠ¸ë¦­:');
      _logging.info('  - signalRms: ${metrics.signalRms.toStringAsFixed(4)}');
      _logging.info('  - signalDb: ${metrics.signalDb.toStringAsFixed(2)} dB');
      _logging.info('  - ambientDb: ${metrics.ambientDb.toStringAsFixed(2)} dB');
      _logging.info('  - SNR: ${metrics.snrDb.toStringAsFixed(2)} dB');

      // 11. ìƒíƒœ íŒì •
      _logging.info('ğŸ” ìƒíƒœ íŒì • ì¤‘...');
      final decision = _classify(metrics);
      _logging.info('âœ… íŒì • ê²°ê³¼: ${decision.status.name} - ${decision.message}');

      if (decision.status == MicDiagnosticStatus.ok) {
        return MicDiagnosticResult(
          timestamp: timestamp,
          status: MicDiagnosticStatus.ok,
          peakRms: metrics.signalRms,
          peakDb: metrics.signalDb,
          ambientDb: metrics.ambientDb,
          snrDb: metrics.snrDb,
          message: decision.message,
        );
      }

      return MicDiagnosticResult(
        timestamp: timestamp,
        status: decision.status,
        peakRms: metrics.signalRms,
        peakDb: metrics.signalDb,
        ambientDb: metrics.ambientDb,
        snrDb: metrics.snrDb,
        message: decision.message,
        hints: decision.hints,
      );
    } catch (e, stackTrace) {
      _logging.error('âŒ ë§ˆì´í¬ ì§„ë‹¨ ì¤‘ ì˜ˆì™¸ ë°œìƒ', error: e, stackTrace: stackTrace);
      _logging.error('ì—ëŸ¬ íƒ€ì…: ${e.runtimeType}');
      _logging.error('ì—ëŸ¬ ë©”ì‹œì§€: $e');

      // ì—ëŸ¬ íƒ€ì…ë³„ íŒíŠ¸ ì œê³µ
      String detailedMessage = 'ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.';
      List<String> errorHints = [
        'ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”',
        'ì•±ì„ ì¬ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”',
      ];

      if (e.toString().contains('permission') ||
          e.toString().contains('Permission')) {
        detailedMessage = 'ë§ˆì´í¬ ê¶Œí•œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.';
        errorHints = [
          'Windows ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”',
          'ì•±ì„ ì¬ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”',
        ];
      } else if (e.toString().contains('device') ||
          e.toString().contains('Device')) {
        detailedMessage = 'ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.';
        errorHints = [
          'ë§ˆì´í¬ë¥¼ ë‹¤ì‹œ ì—°ê²°í•´ë³´ì„¸ìš”',
          'Windows ì‚¬ìš´ë“œ ì„¤ì •ì—ì„œ ê¸°ë³¸ ì¥ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”',
        ];
      } else if (e.toString().contains('codec') ||
          e.toString().contains('encoder')) {
        detailedMessage = 'ì˜¤ë””ì˜¤ ì¸ì½”ë” ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆì–´ìš”.';
        errorHints = [
          'Windows Media Feature Packì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”',
          'ì‹œìŠ¤í…œì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”',
        ];
      }

      return MicDiagnosticResult(
        timestamp: timestamp,
        status: MicDiagnosticStatus.failure,
        message: detailedMessage,
        hints: errorHints,
      );
    } finally {
      try {
        await recorder.stop();
      } catch (_) {}
      try {
        await recorder.dispose();
      } catch (_) {}
      await subscription?.cancel();
      if (tempFilePath != null) {
        final file = File(tempFilePath);
        if (await file.exists()) {
          unawaited(file.delete());
        }
      }
    }
  }

  static const double _normalThresholdDb = -24.0;
  static const double _quietOkThresholdDb = -40.0;
  static const double _quietSnrAllowanceDb = 3.5;
  static const double _quietAcceptableDb = -48.0;
  static const double _snrToleranceDb = -0.5;
  static const double _minDb = -80.0;

  static const double _noSignalThresholdDb = -70.0;
  static const double _extremeLowThresholdDb = -60.0;

  double _normalizeAmplitude(Amplitude amplitude) {
    double sample = amplitude.current;
    if (sample == 0 && amplitude.max != 0) {
      sample = amplitude.max;
    }

    if (sample <= 0) {
      return math.pow(10, sample / 20).toDouble().clamp(0.0, 1.0);
    }

    if (sample <= 1.0) {
      return sample.clamp(0.0, 1.0);
    }

    final normalized = sample / 32768.0;
    if (!normalized.isFinite || normalized.isNaN) {
      return 0.0;
    }
    return normalized.clamp(0.0, 1.0);
  }

  _DiagnosticMetrics _calculateMetrics({
    required List<_AmplitudeSample> samples,
    required Duration sampleWindow,
    required Duration ambientWindow,
  }) {
    if (samples.isEmpty) {
      return const _DiagnosticMetrics.zero();
    }

    final startTime = samples.first.timestamp;
    final ambientDeadline = startTime.add(ambientWindow);

    final ambientValues = <double>[];
    final signalValues = <double>[];

    for (final sample in samples) {
      if (sample.timestamp.isBefore(ambientDeadline)) {
        ambientValues.add(sample.value);
      } else {
        signalValues.add(sample.value);
      }
    }

    if (signalValues.isEmpty) {
      signalValues.addAll(ambientValues);
    }

    final ambientRms = _rms(ambientValues);
    final signalRms = _rms(signalValues);

    final ambientDb = _toDb(ambientRms);
    final signalDb = _toDb(signalRms);
    final snrDb = _snrDb(signalRms, ambientRms);

    return _DiagnosticMetrics(
      signalRms: signalRms,
      ambientRms: ambientRms,
      signalDb: signalDb,
      ambientDb: ambientDb,
      snrDb: snrDb,
    );
  }

  _DiagnosticDecision _classify(_DiagnosticMetrics metrics) {
    final signalDb = metrics.signalDb;
    final snrDb = metrics.snrDb;

    if (signalDb < _noSignalThresholdDb) {
      return _DiagnosticDecision(
        status: MicDiagnosticStatus.noSignal,
        message: 'ë§ˆì´í¬ ì‹ í˜¸ê°€ ì „í˜€ ê°ì§€ë˜ì§€ ì•Šì•„ìš”. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.',
        hints: const [
          'ë§ˆì´í¬ ì¼€ì´ë¸”ì´ PCì— ì œëŒ€ë¡œ ê½‚í˜€ ìˆëŠ”ì§€ í™•ì¸',
          'USB ë§ˆì´í¬ë¼ë©´ ë‹¤ë¥¸ í¬íŠ¸ì— ì—°ê²°í•´ë³´ì„¸ìš”',
          'ë¸”ë£¨íˆ¬ìŠ¤ ë§ˆì´í¬ë¼ë©´ í˜ì–´ë§ ìƒíƒœ í™•ì¸',
        ],
      );
    }

    if (signalDb < _extremeLowThresholdDb) {
      return _DiagnosticDecision(
        status: MicDiagnosticStatus.lowInput,
        message: 'ì†Œë¦¬ê°€ ê±°ì˜ ë“¤ì–´ì˜¤ì§€ ì•Šì•„ìš”. ë§ˆì´í¬ ìŒì†Œê±° ìŠ¤ìœ„ì¹˜ë‚˜ ë³¼ë¥¨ì„ í™•ì¸í•˜ì„¸ìš”.',
        hints: const [
          'í—¤ë“œì…‹ ìŒì†Œê±° ìŠ¤ìœ„ì¹˜ í•´ì œ',
          'Windows ì…ë ¥ ì¥ì¹˜ ë³¼ë¥¨ì„ ë†’ì—¬ì£¼ì„¸ìš”',
          'ë§ˆì´í¬ë¥¼ ì… ê°€ê¹Œì´ì— ë‘ê³  ë§í•´ë³´ì„¸ìš”',
        ],
      );
    }

    final quietButClear =
        signalDb >= _quietOkThresholdDb && snrDb >= _quietSnrAllowanceDb;
    final quietButAcceptable =
        signalDb >= _quietAcceptableDb && snrDb >= _snrToleranceDb;
    final normalLevel = signalDb >= _normalThresholdDb;

    if (normalLevel || quietButClear || quietButAcceptable) {
      final description = quietButClear
          ? 'ì¡°ìš©í•œ í™˜ê²½ì´ì§€ë§Œ ìŒì„±ì´ ë˜ë ·í•˜ê²Œ ê°ì§€ë˜ê³  ìˆì–´ìš”.'
          : quietButAcceptable
              ? 'ë…¹ìŒì€ ê°€ëŠ¥í•˜ì§€ë§Œ ì…ë ¥ì´ ë‹¤ì†Œ ë‚®ì•„ìš”. í•„ìš”í•˜ë©´ ë§ˆì´í¬ ìœ„ì¹˜ë‚˜ ë³¼ë¥¨ì„ ì¡°ê¸ˆë§Œ ì¡°ì •í•´ ì£¼ì„¸ìš”.'
              : 'ë§ˆì´í¬ ì…ë ¥ì´ ì •ìƒì´ì—ìš”.';
      return _DiagnosticDecision(
        status: MicDiagnosticStatus.ok,
        message: description,
      );
    }

    if (signalDb >= _quietOkThresholdDb) {
      return _DiagnosticDecision(
        status: MicDiagnosticStatus.lowInput,
        message: 'ì…ë ¥ ë ˆë²¨ì´ ì¡°ê¸ˆ ë‚®ì•„ìš”. ë§ˆì´í¬ ìœ„ì¹˜ë‚˜ ë³¼ë¥¨ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.',
        hints: const [
          'ë§ˆì´í¬ë¥¼ ì… ê°€ê¹Œì´ì— ë‘ê³  ë§í•´ë³´ì„¸ìš”.',
          'Windows ì…ë ¥ ì¥ì¹˜ ë³¼ë¥¨ì„ ì¡°ê¸ˆ ë†’ì—¬ì£¼ì„¸ìš”.',
        ],
      );
    }

    return _DiagnosticDecision(
      status: MicDiagnosticStatus.lowInput,
      message: 'ë§ˆì´í¬ ì—°ê²°ì´ë‚˜ ìŒì†Œê±° ìŠ¤ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.',
      hints: const [
        'ë§ˆì´í¬ ì¼€ì´ë¸”ê³¼ ì—°ê²° ìƒíƒœ í™•ì¸',
        'í—¤ë“œì…‹ ìŒì†Œê±° ìŠ¤ìœ„ì¹˜ í•´ì œ',
        'Windows ì…ë ¥ ì¥ì¹˜ ì„¤ì •ì—ì„œ ê¸°ë³¸ ì¥ì¹˜ í™•ì¸',
      ],
    );
  }

  double _rms(List<double> values) {
    if (values.isEmpty) {
      return 0.0;
    }
    var sumSquares = 0.0;
    for (final value in values) {
      sumSquares += value * value;
    }
    return math.sqrt(sumSquares / values.length);
  }

  double _toDb(double rms) {
    if (rms <= 0) {
      return _minDb;
    }
    return 20 * (math.log(rms) / math.ln10);
  }

  double _snrDb(double signalRms, double ambientRms) {
    final epsilon = 1e-9;
    return 20 *
        (math.log((signalRms + epsilon) / (ambientRms + epsilon)) / math.ln10);
  }

  String _extensionForEncoder(AudioEncoder encoder) {
    switch (encoder) {
      case AudioEncoder.aacLc:
        return '.m4a';
      case AudioEncoder.opus:
        return '.opus';
      case AudioEncoder.wav:
        return '.wav';
      default:
        return '.m4a';
    }
  }
}

class _AmplitudeSample {
  _AmplitudeSample(this.timestamp, this.value);

  final DateTime timestamp;
  final double value;
}

class _DiagnosticMetrics {
  const _DiagnosticMetrics({
    required this.signalRms,
    required this.ambientRms,
    required this.signalDb,
    required this.ambientDb,
    required this.snrDb,
  });

  const _DiagnosticMetrics.zero()
      : signalRms = 0.0,
        ambientRms = 0.0,
        signalDb = MicDiagnosticsService._minDb,
        ambientDb = MicDiagnosticsService._minDb,
        snrDb = 0.0;

  final double signalRms;
  final double ambientRms;
  final double signalDb;
  final double ambientDb;
  final double snrDb;
}

class _DiagnosticDecision {
  const _DiagnosticDecision({
    required this.status,
    required this.message,
    this.hints = const <String>[],
  });

  final MicDiagnosticStatus status;
  final String message;
  final List<String> hints;
}
