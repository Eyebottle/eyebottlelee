import 'dart:async';
import 'dart:io';
import 'dart:math' as math;

import 'package:flutter/services.dart';
import 'package:path/path.dart' as path;
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';

import 'settings_service.dart';
import 'logging_service.dart';
import 'audio_converter_service.dart';
import '../models/recording_profile.dart';

class AudioService {
  final AudioRecorder _recorder = AudioRecorder();
  StreamSubscription<Amplitude>? _amplitudeSubscription;
  Timer? _segmentTimer;
  final LoggingService _logging = LoggingService();
  final AudioConverterService _audioConverterService = AudioConverterService();

  bool _isRecording = false;
  bool _vadEnabled = true;
  double vadThreshold = 0.006; // RMS ê¸°ë°˜ VAD ì„ê³„ê°’
  int _silenceMs = 0;
  bool _pausedByVad = false;
  Timer? _resumeTimer;
  // ë³´ê´€ ì£¼ê¸° (ê¸°ë³¸ 7ì¼)
  Duration? retention;
  RecordingProfile _profile =
      RecordingProfile.presets[RecordingQualityProfile.balanced]!;

  DateTime? _currentSegmentStartedAt;
  double _makeupGainDb = 0.0;

  // ì½œë°± í•¨ìˆ˜ë“¤
  Function(double)? onAmplitudeChanged;
  Function(String)? onFileSegmentCreated;
  Function(DateTime startTime)? onRecordingStarted;
  Function(DateTime startTime, DateTime stopTime, Duration recordedDuration)?
      onRecordingStopped;

  bool get isRecording => _isRecording;
  bool get vadEnabled => _vadEnabled;
  DateTime? _sessionStartTime;

  // ì§€ì›ë˜ëŠ” ì½”ë± ì €ì¥
  AudioEncoder? _supportedEncoder;
  bool _encoderChecked = false;
  AudioEncoder? _currentEncoder;

  AudioService() {
    unawaited(_logging.ensureInitialized());
  }

  /// ì§€ì›ë˜ëŠ” ì½”ë± í™•ì¸ ë° ì„ íƒ
  Future<AudioEncoder> _selectSupportedEncoder({
    Set<AudioEncoder> excludeEncoders = const {},
  }) async {
    if (_encoderChecked && _supportedEncoder != null) {
      if (!excludeEncoders.contains(_supportedEncoder)) {
        _logging.info('ğŸ’¡ ìºì‹œëœ ì½”ë± ì‚¬ìš©: ${_supportedEncoder!.name}');
        return _supportedEncoder!;
      }
      _logging.info(
          'ğŸ’¡ ìºì‹œëœ ì½”ë± ${_supportedEncoder!.name}ì´(ê°€) ì œì™¸ ëŒ€ìƒì´ë¯€ë¡œ ìºì‹œë¥¼ ë¬´íš¨í™”í•©ë‹ˆë‹¤.');
      _encoderChecked = false;
      _supportedEncoder = null;
    }

    _logging.info('ğŸ” ì§€ì›ë˜ëŠ” ì½”ë± í™•ì¸ ì¤‘...');

    // ì½”ë± ìš°ì„ ìˆœìœ„: AAC > Opus > WAV
    final encodersToTry = <AudioEncoder>[
      AudioEncoder.aacLc,
      AudioEncoder.opus,
      AudioEncoder.wav,
    ];

    for (final encoder in encodersToTry) {
      if (excludeEncoders.contains(encoder)) {
        _logging.info('  - ${encoder.name}: ì œì™¸ ëª©ë¡ì— ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤');
        continue;
      }
      try {
        final isSupported = await _recorder.isEncoderSupported(encoder);

        if (isSupported) {
          _supportedEncoder = encoder;
          _encoderChecked = true;
          _logging.info('âœ… ì„ íƒëœ ì½”ë±: ${encoder.name}');
          return encoder;
        }
      } catch (e) {
        _logging.warning('ì½”ë± ${encoder.name} í™•ì¸ ì¤‘ ì—ëŸ¬: $e');
      }
    }

    // ìµœí›„ì˜ ìˆ˜ë‹¨: WAV (ì œì™¸ë˜ì§€ ì•Šì€ ê²½ìš°)
    if (!excludeEncoders.contains(AudioEncoder.wav)) {
      _logging.error('âŒ ì§€ì›ë˜ëŠ” ì½”ë±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. WAVë¥¼ ê°•ì œ ì‚¬ìš©í•©ë‹ˆë‹¤.');
      _supportedEncoder = AudioEncoder.wav;
      _encoderChecked = true;
      return AudioEncoder.wav;
    }

    throw Exception('ì§€ì›ë˜ëŠ” ì½”ë±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (exclude=${excludeEncoders.map((e) => e.name).join(', ')})');
  }

  /// ë…¹ìŒ ì‹œì‘
  Future<void> startRecording(
      {Duration segmentDuration = const Duration(minutes: 10)}) async {
    _logging.info('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘ ìš”ì²­ (ì„¸ê·¸ë¨¼íŠ¸ ì£¼ê¸°: ${segmentDuration.inMinutes}ë¶„)');

    try {
      // 1. ê¶Œí•œ í™•ì¸
      _logging.info('ğŸ“‹ ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ì¤‘...');
      final hasPermission = await _recorder.hasPermission();
      _logging.info('ê¶Œí•œ ìƒíƒœ: hasPermission=$hasPermission');

      if (hasPermission == false) {
        _logging.warning('âš ï¸ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
        throw Exception('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      }

      // 2. ë…¹ìŒ ì„¤ì • ì •ë³´ ì¶œë ¥
      _logging.info('ğŸšï¸ ë…¹ìŒ ì„¤ì •:');
      _logging.info('  - í”„ë¡œí•„: ${_profile.id.name}');
      _logging.info('  - ë¹„íŠ¸ë ˆì´íŠ¸: ${_profile.bitRate} bps');
      _logging.info('  - ìƒ˜í”Œë ˆì´íŠ¸: ${_profile.sampleRate} Hz');
      _logging.info('  - ë©”ì´í¬ì—… ê²Œì¸: ${_makeupGainDb.toStringAsFixed(1)} dB');
      _logging.info('  - VAD í™œì„±í™”: $_vadEnabled');
      if (_vadEnabled) {
        _logging.info('  - VAD ì„ê³„ê°’: ${vadThreshold.toStringAsFixed(4)}');
      }

      // 3. ë…¹ìŒ ì‹œì‘ (í´ë°± ë¡œì§ í¬í•¨)
      _logging.info('ğŸ”´ ë…¹ìŒ ì‹œì‘ ì‹œë„...');

      bool recordingStarted = false;
      Exception? lastError;

      final attemptedEncoders = <AudioEncoder>{};

      while (!recordingStarted) {
        RecordConfig config;
        AudioEncoder encoder;

        try {
          config = await _buildRecordConfig(excludeEncoders: attemptedEncoders);
          encoder = config.encoder;
        } on Exception catch (e, st) {
          _logging.error('ì‚¬ìš©í•  ì½”ë±ì„ ì„ íƒí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤', error: e, stackTrace: st);
          lastError = e;
          break;
        }

        attemptedEncoders.add(encoder);
        final filePath = await _generateFilePathForEncoder(encoder);

        try {
          await _recorder.start(
            config,
            path: filePath,
          );

          _logging.info('âœ… ë…¹ìŒ ì‹œì‘ ì„±ê³µ (ì½”ë±: ${encoder.name})');
          _currentSegmentStartedAt = DateTime.now();
          recordingStarted = true;
          _currentEncoder = encoder;
          _supportedEncoder = encoder;
          _encoderChecked = true;
        } catch (e, st) {
          final exception = e is Exception ? e : Exception(e.toString());
          lastError = exception;
          _logging.error('[ì‹œë„ ${attemptedEncoders.length}] ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨ (${encoder.name})',
              error: e, stackTrace: st);

          // PlatformExceptionì€ ëŒ€ë¶€ë¶„ ì½”ë±/ì„¤ì • ë¬¸ì œ â†’ ë‹¤ìŒ ì½”ë±ìœ¼ë¡œ í´ë°±
          if (e is PlatformException) {
            _logging.warning('ì½”ë± ì—ëŸ¬ - ë‹¤ìŒ ì½”ë±ìœ¼ë¡œ í´ë°±');
            _encoderChecked = false;
            if (_supportedEncoder == encoder) {
              _supportedEncoder = null;
            }
            _currentEncoder = null;
            continue;
          }

          // PlatformExceptionì´ ì•„ë‹Œ ì—ëŸ¬ëŠ” ì‹¬ê°í•œ ë¬¸ì œ â†’ ì¬ì‹œë„ ì¤‘ë‹¨
          _logging.error('ì½”ë±ê³¼ ë¬´ê´€í•œ ì‹¬ê°í•œ ì—ëŸ¬ ë°œìƒ - ì¬ì‹œë„ ì¤‘ë‹¨');
          throw exception;
        }
      }

      // ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ
      if (!recordingStarted) {
        _logging.error('ëª¨ë“  ì½”ë±ìœ¼ë¡œ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨');
        throw lastError ?? Exception('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨');
      }

      _isRecording = true;

      // 5. ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì´ë¨¸ ì‹œì‘
      _logging.info('â° ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì´ë¨¸ ì‹œì‘ (${segmentDuration.inMinutes}ë¶„ ì£¼ê¸°)');
      _startSegmentTimer(segmentDuration);

      // 6. ì§„í­ ëª¨ë‹ˆí„°ë§ ì‹œì‘
      _logging.info('ğŸ“Š ì§„í­ ëª¨ë‹ˆí„°ë§ ì‹œì‘');
      _startAmplitudeMonitoring();

      final startedAt = DateTime.now();
      _sessionStartTime = startedAt;
      if (onRecordingStarted != null) {
        onRecordingStarted!(startedAt);
      }

      // 7. ë³´ê´€ ì •ì±… ì ìš©
      _logging.info('ğŸ§¹ ë³´ê´€ ì •ì±… ì ìš© ì¤‘...');
      unawaited(_pruneOldFiles());

      _logging.info('âœ… ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ');
    } catch (e, st) {
      _isRecording = false;
      _logging.error('âŒ ë…¹ìŒ ì‹œì‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ', error: e, stackTrace: st);
      _logging.error('ì—ëŸ¬ íƒ€ì…: ${e.runtimeType}');
      _logging.error('ì—ëŸ¬ ë©”ì‹œì§€: $e');
      throw Exception('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e');
    }
  }

  /// ë…¹ìŒ ì¤‘ì§€
  Future<String?> stopRecording() async {
    _logging.info('â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ìš”ì²­');

    try {
      final stoppedAt = DateTime.now();
      final startTime = _sessionStartTime;
      final currentEncoder = _currentEncoder;

      // 1. ë…¹ìŒ ì¤‘ì§€
      _logging.info('ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ ì‹œë„...');
      final filePath = await _recorder.stop();
      _logging.info('âœ… ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ');
      _isRecording = false;
      _currentEncoder = null;

      // 2. íƒ€ì´ë¨¸ ë° ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      _logging.info('ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...');
      _segmentTimer?.cancel();
      _amplitudeSubscription?.cancel();
      _logging.info('âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ');

      // 3. ì„¸ì…˜ í†µê³„
      if (startTime != null) {
        final duration = stoppedAt.difference(startTime);
        _logging.info('ğŸ“Š ì„¸ì…˜ í†µê³„:');
        _logging.info('  - ì‹œì‘ ì‹œê°: ${startTime.toIso8601String()}');
        _logging.info('  - ì¢…ë£Œ ì‹œê°: ${stoppedAt.toIso8601String()}');
        _logging.info('  - ì´ ë…¹ìŒ ì‹œê°„: ${_formatDuration(duration)}');

        if (onRecordingStopped != null && duration > Duration.zero) {
          onRecordingStopped!(startTime, stoppedAt, duration);
        }
      }
      _sessionStartTime = null;

      // 4. íŒŒì¼ ì •ë³´
      if (filePath != null) {
        _logging.info('ğŸ“ ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸: $filePath');
        final file = File(filePath);
        if (await file.exists()) {
          final fileSize = await file.length();
          _logging.info('  - íŒŒì¼ í¬ê¸°: ${_formatBytes(fileSize)}');
        }
        final segmentDuration = _estimateSegmentDuration(stoppedAt);
        unawaited(
          _logSegmentMetadata(
            filePath,
            segmentDuration,
            encoder: currentEncoder,
          ),
        );

        // WAV ìë™ ë³€í™˜ (ë§ˆì§€ë§‰ íŒŒì¼ë„ ë³€í™˜)
        if (currentEncoder == AudioEncoder.wav) {
          _logging.info('ğŸ’¡ ë§ˆì§€ë§‰ WAV íŒŒì¼ ë³€í™˜ ì˜ˆì•½');
          unawaited(_scheduleWavConversion(filePath, skipRecordingCheck: true));
        }
      }
      _currentSegmentStartedAt = null;

      // 5. ë³´ê´€ ì •ì±… ì ìš©
      _logging.info('ğŸ§¹ ë³´ê´€ ì •ì±… ì ìš© ì¤‘...');
      await _pruneOldFiles();

      _logging.info('âœ… ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ');
      return filePath;
    } catch (e, st) {
      _logging.error('âŒ ë…¹ìŒ ì¤‘ì§€ ì¤‘ ì˜ˆì™¸ ë°œìƒ', error: e, stackTrace: st);
      _logging.error('ì—ëŸ¬ íƒ€ì…: ${e.runtimeType}');
      _logging.error('ì—ëŸ¬ ë©”ì‹œì§€: $e');
      throw Exception('ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨: $e');
    }
  }

  String _formatDuration(Duration duration) {
    final hours = duration.inHours;
    final minutes = duration.inMinutes.remainder(60);
    final seconds = duration.inSeconds.remainder(60);
    if (hours > 0) {
      return '$hoursì‹œê°„ $minutesë¶„ $secondsì´ˆ';
    } else if (minutes > 0) {
      return '$minutesë¶„ $secondsì´ˆ';
    } else {
      return '$secondsì´ˆ';
    }
  }

  String _formatBytes(int bytes) {
    if (bytes < 1024) return '$bytes B';
    if (bytes < 1024 * 1024) return '${(bytes / 1024).toStringAsFixed(1)} KB';
    return '${(bytes / (1024 * 1024)).toStringAsFixed(2)} MB';
  }

  /// íŒŒì¼ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 
  Future<void> splitSegment() async {
    if (!_isRecording) return;

    try {
      // í˜„ì¬ ë…¹ìŒ ì¤‘ì§€
      final segmentStopTime = DateTime.now();
      final completedEncoder = _currentEncoder;
      final completedPath = await _recorder.stop();

      // ì™„ë£Œëœ íŒŒì¼ ì½œë°± í˜¸ì¶œ
      if (completedPath != null && onFileSegmentCreated != null) {
        onFileSegmentCreated!(completedPath);
      }
      if (completedPath != null) {
        _logging.info('ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì™„ë£Œ');
        _logging.debug('ì™„ë£Œëœ ì„¸ê·¸ë¨¼íŠ¸ ê²½ë¡œ: $completedPath');
        final segmentDuration = _estimateSegmentDuration(segmentStopTime);
        unawaited(
          _logSegmentMetadata(
            completedPath,
            segmentDuration,
            encoder: completedEncoder,
          ),
        );
      }

      // ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì¦‰ì‹œ ì¬ì‹œì‘
      final config = await _buildRecordConfig();
      final newEncoder = config.encoder;
      final newFilePath = await _generateFilePathForEncoder(newEncoder);
      _currentSegmentStartedAt = DateTime.now();
      await _recorder.start(
        config,
        path: newFilePath,
      );
      _currentEncoder = newEncoder;

      _logging.debug('ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘: $newFilePath');

      // WAV ìë™ ë³€í™˜ ë¡œì§ (ì¡°ê±´ë¶€ ì‹¤í–‰)
      // ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì‹œì—ëŠ” ë…¹ìŒì´ ê³„ì† ì§„í–‰ ì¤‘ì´ì§€ë§Œ,
      // ë…¹ìŒ ì¤‘ì§€ ì§ì „ì— ë¶„í• ëœ íŒŒì¼ë„ ë³€í™˜ë˜ì–´ì•¼ í•˜ë¯€ë¡œ skipRecordingCheck: true ì‚¬ìš©
      if (completedEncoder == AudioEncoder.wav && completedPath != null) {
        unawaited(_scheduleWavConversion(completedPath, skipRecordingCheck: true));
      }

      // ë³´ê´€ ì •ì±… ì ìš© (ë°±ê·¸ë¼ìš´ë“œ)
      unawaited(_pruneOldFiles());
    } catch (e) {
      _logging.error('ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì‹¤íŒ¨', error: e);
    }
  }

  /// WAV íŒŒì¼ ë³€í™˜ ìŠ¤ì¼€ì¤„ë§
  ///
  /// **ë™ì‘:**
  /// 1. ì„¤ì •ì—ì„œ ìë™ ë³€í™˜ í™œì„±í™” í™•ì¸
  /// 2. ì§€ì—° ì‹œê°„ë§Œí¼ ëŒ€ê¸° (ë…¹ìŒ ì•ˆì •í™”)
  /// 3. ì—¬ì „íˆ ë…¹ìŒ ì¤‘ì¸ì§€ í™•ì¸ (skipRecordingCheckê°€ falseì¸ ê²½ìš°)
  /// 4. ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ WAV â†’ AAC/Opus ë³€í™˜
  ///
  /// **ë§¤ê°œë³€ìˆ˜:**
  /// - `wavPath`: ë³€í™˜í•  WAV íŒŒì¼ ê²½ë¡œ
  /// - `skipRecordingCheck`: trueë©´ ë…¹ìŒ ì¤‘ì§€ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ë³€í™˜ (ê¸°ë³¸ê°’: false)
  Future<void> _scheduleWavConversion(String wavPath, {bool skipRecordingCheck = false}) async {
    try {
      // ì„¤ì • ë¡œë“œ
      final settings = SettingsService();
      final isEnabled = await settings.isWavAutoConvertEnabled();

      if (!isEnabled) {
        _logging.debug('WAV ìë™ ë³€í™˜ ë¹„í™œì„±í™”ë¨ - ë³€í™˜ ê±´ë„ˆëœ€');
        return;
      }

      final delaySeconds = await settings.getConversionDelay();
      final targetEncoder = await settings.getWavTargetEncoder();

      _logging.info(
        'WAV ë³€í™˜ ì˜ˆì•½: ${path.basename(wavPath)} â†’ ${targetEncoder.name} '
        '(${delaySeconds}ì´ˆ í›„ ì‹œì‘)',
      );

      // ì§€ì—° ì‹¤í–‰ (ë…¹ìŒ ì•ˆì •í™” ì‹œê°„ í™•ë³´)
      Future.delayed(Duration(seconds: delaySeconds), () async {
        // ì•ˆì „ì„± ì²´í¬: ì—¬ì „íˆ ë…¹ìŒ ì¤‘ì¸ê°€? (skipRecordingCheckê°€ falseì¸ ê²½ìš°ë§Œ)
        if (!skipRecordingCheck && !_isRecording) {
          _logging.warning('ë…¹ìŒ ì¤‘ì§€ë¨ - WAV ë³€í™˜ ì·¨ì†Œ: ${path.basename(wavPath)}');
          return;
        }

        try {
          _logging.info('WAV ë³€í™˜ ì‹œì‘: ${path.basename(wavPath)}');

          final outputPath = await _audioConverterService.convertWavToEncoded(
            wavPath: wavPath,
            targetEncoder: targetEncoder,
            bitRate: _profile.bitRate,
            sampleRate: _profile.sampleRate,
            deleteOriginal: true, // ë³€í™˜ ì„±ê³µ ì‹œ ì›ë³¸ ì‚­ì œ
          );

          if (outputPath != null) {
            _logging.info('ë³€í™˜ ì™„ë£Œ: ${path.basename(outputPath)}');
          } else {
            _logging.warning('ë³€í™˜ ì‹¤íŒ¨: ì›ë³¸ ìœ ì§€ë¨ (${path.basename(wavPath)})');
          }
        } catch (e, stackTrace) {
          _logging.error('WAV ë³€í™˜ ì˜ˆì™¸', error: e, stackTrace: stackTrace);
        }
      });
    } catch (e, stackTrace) {
      _logging.error('WAV ë³€í™˜ ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨', error: e, stackTrace: stackTrace);
    }
  }

  /// ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì´ë¨¸ ì‹œì‘
  void _startSegmentTimer(Duration duration) {
    _segmentTimer = Timer.periodic(duration, (_) => splitSegment());
  }

  /// ì˜¤ë””ì˜¤ ë ˆë²¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘
  void _startAmplitudeMonitoring() {
    _amplitudeSubscription = _recorder
        .onAmplitudeChanged(const Duration(milliseconds: 200))
        .listen((amplitude) {
      final level = _normalizeAmplitude(amplitude);
      final adjustedLevel = _applyMakeupGain(level);

      // UI ì½œë°± í˜¸ì¶œ
      if (onAmplitudeChanged != null) {
        onAmplitudeChanged!(adjustedLevel);
      }

      // ê°„ë‹¨í•œ VAD ë¡œì§ (ì„ íƒì )
      if (_vadEnabled) _processVAD(adjustedLevel);
    });
  }

  double _normalizeAmplitude(Amplitude amplitude) {
    double sample = amplitude.current;
    if (sample == 0 && amplitude.max != 0) {
      sample = amplitude.max;
    }
    double normalized;

    if (sample <= 0) {
      // record íŒ¨í‚¤ì§€ëŠ” dB(-160~0) ê°’ì„ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ 0~1ë¡œ ë³€í™˜
      normalized = math.pow(10, sample / 20).toDouble();
    } else if (sample <= 1.0) {
      normalized = sample;
    } else {
      normalized = sample / 32768.0;
    }

    if (normalized.isNaN || !normalized.isFinite) {
      return 0.0;
    }

    // ê°ë§ˆ ë³´ì • ì ìš©: ì‘ì€ ì†Œë¦¬ë¥¼ ë” ì˜ ë³´ì´ê²Œ í•¨
    // pow(x, 0.3)ì€ ì‘ì€ ê°’ì„ í¬ê²Œ, í° ê°’ì€ ì ë‹¹íˆ ìœ ì§€
    // ì˜ˆ: 0.01 -> 0.22, 0.1 -> 0.50, 0.5 -> 0.81
    normalized = math.pow(normalized, 0.3).toDouble();

    return normalized.clamp(0.0, 1.0);
  }

  /// Voice Activity Detection ì²˜ë¦¬
  void _processVAD(double level) {
    const windowMs = 200; // onAmplitudeChanged ì£¼ê¸°ì™€ ë™ì¼
    const silenceHoldMs = 4000; // 4ì´ˆ ë¬´ìŒ ì‹œ ì¼ì‹œì •ì§€
    const resumeDelayMs = 500; // ì¬ê°œ ì§€ì—°

    // ë¬´ìŒ ëˆ„ì /í•´ì œ
    if (level < vadThreshold) {
      _silenceMs += windowMs;
    } else {
      _silenceMs = 0;
      if (_pausedByVad) {
        _resumeTimer?.cancel();
        _resumeTimer =
            Timer(const Duration(milliseconds: resumeDelayMs), () async {
          try {
            await _recorder.resume();
            _pausedByVad = false;
            _logging.debug('VAD: ìŒì„± ê°ì§€ë¡œ ë…¹ìŒ ì¬ê°œ');
          } catch (e) {
            _logging.error('VAD ì¬ê°œ ì‹¤íŒ¨', error: e);
          }
        });
      }
    }

    // ì¼ì • ë¬´ìŒ ì§€ì† ì‹œ ì¼ì‹œì •ì§€
    if (!_pausedByVad && _silenceMs >= silenceHoldMs) {
      _resumeTimer?.cancel();
      _silenceMs = 0;
      () async {
        try {
          await _recorder.pause();
          _pausedByVad = true;
          _logging.debug('VAD: ë¬´ìŒ ì§€ì†ìœ¼ë¡œ ë…¹ìŒ ì¼ì‹œì •ì§€');
        } catch (e) {
          _logging.error('VAD ì¼ì‹œì •ì§€ ì‹¤íŒ¨', error: e);
        }
      }();
    }
  }

  /// ì™¸ë¶€ì—ì„œ VAD êµ¬ì„± ì ìš©
  void configureVad({required bool enabled, required double threshold}) {
    _vadEnabled = enabled;
    vadThreshold = threshold;
    _logging.info('VAD ì„¤ì • ë³€ê²½ (enabled=$enabled, threshold=$threshold)');
  }

  /// ë³´ê´€ ì£¼ê¸° êµ¬ì„± (null ì´ë©´ ì˜êµ¬ ë³´ì¡´)
  void configureRetention(Duration? duration) {
    retention = duration;
    if (duration == null) {
      _logging.info('ë³´ê´€ ì£¼ê¸° ì„¤ì •: ì˜êµ¬ ë³´ì¡´');
    } else {
      _logging.info('ë³´ê´€ ì£¼ê¸° ì„¤ì •: ${duration.inDays}ì¼');
    }
  }

  void configureRecordingProfile(RecordingQualityProfile profileId) {
    _profile = RecordingProfile.resolve(profileId);
    _logging.info(
      'ë…¹ìŒ í’ˆì§ˆ í”„ë¡œí•„ ë³€ê²½: ${_profile.id.name} (bitRate=${_profile.bitRate}, sampleRate=${_profile.sampleRate})',
    );
  }

  RecordingProfile get currentProfile => _profile;

  void configureMakeupGain(double gainDb) {
    final normalized = gainDb.clamp(0, 12).toDouble();
    _makeupGainDb = normalized;
    _logging.info('ë©”ì´í¬ì—… ê²Œì¸ ì„¤ì •: ${_makeupGainDb.toStringAsFixed(1)} dB');
  }

  /// íŒŒì¼ ê²½ë¡œ ìƒì„±
  Future<String> getResolvedSaveRootPath() async {
    final directory = await _getRecordingDirectory();
    return directory.path;
  }

  Future<String> _generateFilePathForEncoder(AudioEncoder encoder) async {
    final dateDirectory = await getTodayRecordingDirectory();
    final now = DateTime.now();
    final extension = _extensionForEncoder(encoder);

    final filename =
        '${now.year}-${_twoDigits(now.month)}-${_twoDigits(now.day)}_'
        '${_twoDigits(now.hour)}-${_twoDigits(now.minute)}-${_twoDigits(now.second)}-${_threeDigits(now.millisecond)}_ì§„ë£Œë…¹ìŒ$extension';
    return path.join(dateDirectory.path, filename);
  }

  /// ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ë…¹ìŒ í´ë”ë¥¼ ìƒì„±/ë°˜í™˜í•œë‹¤.
  Future<Directory> getTodayRecordingDirectory() async {
    final baseDirectory = await _getRecordingDirectory();
    final now = DateTime.now();
    final dateFolderName =
        '${now.year}-${_twoDigits(now.month)}-${_twoDigits(now.day)}';
    final dateDirectory =
        Directory(path.join(baseDirectory.path, dateFolderName));
    if (!await dateDirectory.exists()) {
      await dateDirectory.create(recursive: true);
    }
    return dateDirectory;
  }

  /// ë…¹ìŒ ì €ì¥ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (ì„¤ì • í´ë” ìš°ì„ )
  Future<Directory> _getRecordingDirectory() async {
    final settings = SettingsService();
    final saved = await settings.getSaveFolder();
    if (saved != null && saved.isNotEmpty) {
      final dir = Directory(saved);
      if (!await dir.exists()) {
        await dir.create(recursive: true);
      }
      return dir;
    }

    // ê¸°ë³¸ ì•± ë¬¸ì„œ ë””ë ‰í† ë¦¬ í•˜ìœ„ í´ë”
    final appDir = await getApplicationDocumentsDirectory();
    final recordingDir = Directory(path.join(appDir.path, 'EyebottleRecorder'));

    if (!await recordingDir.exists()) {
      await recordingDir.create(recursive: true);
    }

    return recordingDir;
  }

  /// ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬ (ë³´ê´€ ì£¼ê¸° ì´ˆê³¼ íŒŒì¼ ì‚­ì œ)
  Future<void> _pruneOldFiles() async {
    try {
      if (retention == null) {
        return;
      }
      final dir = await _getRecordingDirectory();
      if (!await dir.exists()) return;

      final now = DateTime.now();
      final threshold = now.subtract(retention!);

      await for (final entity
          in dir.list(recursive: true, followLinks: false)) {
        if (entity is File) {
          final lowerPath = entity.path.toLowerCase();
          final isAudioFile = lowerPath.endsWith('.m4a') ||
              lowerPath.endsWith('.opus') ||
              lowerPath.endsWith('.wav');
          if (!isAudioFile) {
            continue;
          }

          final stat = await entity.stat();
          final modified = stat.modified;
          if (modified.isBefore(threshold)) {
            try {
              await entity.delete();
              _logging.debug('ë³´ê´€ê¸°ê°„ ê²½ê³¼ íŒŒì¼ ì‚­ì œ: ${path.basename(entity.path)}');
            } catch (e) {
              _logging.error('íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: ${entity.path}', error: e);
            }
          }
        }
      }

      final basePath = dir.path;
      await _removeEmptyDirectories(dir, basePath: basePath);
    } catch (e) {
      _logging.error('ë³´ê´€ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨', error: e);
    }
  }

  Future<void> _removeEmptyDirectories(Directory directory,
      {required String basePath}) async {
    final entities = await directory.list(followLinks: false).toList();
    for (final entity in entities) {
      if (entity is Directory) {
        await _removeEmptyDirectories(entity, basePath: basePath);
      }
    }

    if (directory.path == basePath) {
      return;
    }

    bool isEmpty = false;
    try {
      isEmpty = await directory.list(followLinks: false).isEmpty;
    } catch (_) {
      // ë¦¬ìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›´ë‹¤.
      return;
    }

    if (isEmpty) {
      try {
        await directory.delete();
      } catch (_) {
        // ì‚­ì œ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ (ë‹¤ìŒ ì •ë¦¬ ì£¼ê¸°ì— ì¬ì‹œë„)
      }
    }
  }

  /// ë‘ ìë¦¬ ìˆ«ì í¬ë§·
  String _twoDigits(int n) => n.toString().padLeft(2, '0');

  String _threeDigits(int n) => n.toString().padLeft(3, '0');

  String _extensionForEncoder(AudioEncoder encoder) {
    switch (encoder) {
      case AudioEncoder.opus:
        return '.opus';
      case AudioEncoder.wav:
        return '.wav';
      default:
        return '.opus';
    }
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _amplitudeSubscription?.cancel();
    _segmentTimer?.cancel();
    _resumeTimer?.cancel();
    _audioConverterService.cancelAll(); // ëŒ€ê¸° ì¤‘ì¸ ë³€í™˜ ì‘ì—… ì·¨ì†Œ
    unawaited(_recorder.dispose());
  }

  Future<RecordConfig> _buildRecordConfig(
      {Set<AudioEncoder> excludeEncoders = const {}}) async {
    final encoder =
        await _selectSupportedEncoder(excludeEncoders: excludeEncoders);
    final config = RecordConfig(
      encoder: encoder,
      bitRate: _profile.bitRate,
      sampleRate: _profile.sampleRate,
      numChannels: 1,
      // autoGain ì œê±° - AAC ì½”ë± í˜¸í™˜ì„± ê°œì„ 
      // mic_diagnostics_serviceì™€ ë™ì¼í•œ ì„¤ì • ì‚¬ìš©
    );
    return config;
  }

  Duration? _estimateSegmentDuration(DateTime stopTime) {
    final startedAt = _currentSegmentStartedAt;
    if (startedAt == null) {
      return null;
    }
    final duration = stopTime.difference(startedAt);
    if (duration.isNegative) {
      return null;
    }
    return duration;
  }

  Future<void> _logSegmentMetadata(String filePath, Duration? duration,
      {AudioEncoder? encoder}) async {
    try {
      final file = File(filePath);
      final bytes = await file.length();
      final sizeInMb = bytes / (1024 * 1024);
      final durationText =
          duration == null ? 'unknown' : '${duration.inSeconds}s';

      final codecLabel = (encoder ?? _currentEncoder)?.name ?? 'unknown';

      _logging.debug(
        'ì„¸ê·¸ë¨¼íŠ¸ ë©”íƒ€: profile=${_profile.id.name}, codec=$codecLabel, bitRate=${_profile.bitRate}, sampleRate=${_profile.sampleRate}, gain=${_makeupGainDb.toStringAsFixed(1)}dB, duration=$durationText, size=${sizeInMb.toStringAsFixed(2)} MB',
      );
    } catch (e) {
      _logging.debug('ì„¸ê·¸ë¨¼íŠ¸ ë©”íƒ€ ê¸°ë¡ ì‹¤íŒ¨: $e');
    }
  }

  double _applyMakeupGain(double level) {
    if (_makeupGainDb <= 0) {
      return level;
    }
    final linear = math.pow(10, _makeupGainDb / 20).toDouble();
    final amplified = (level * linear).clamp(0.0, 1.0);
    return amplified;
  }
}
